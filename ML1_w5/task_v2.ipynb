{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96e16cbcf55ff10922c6025b8e30cb36",
     "grade": false,
     "grade_id": "cell-76f53f536a715153",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is programming assignment for week 5. In this assignment you will be solving classification task. \n",
    "\n",
    "### Grading\n",
    "The assignment contains both automatically graded and peer reviewed tasks. \n",
    "\n",
    "**Automatic grading**\\\n",
    "After you finish solving all the tasks restart the kernel (`kernel -> restart`) and and click button `Validate` to check that everything works as expected. Afterwards, you can submit your work.\n",
    "\n",
    "\n",
    "**Competition**\\\n",
    "In the second part of the assignment you are asked to train the model with the best score on test dataset. Note, that you are not given correct answers on the test dataset. To get your score, use Kaggle competition, that we've created for you. **The score on the Kaggle liderboard will not affect your grade, instead you need to submit your best result to the separate programming assignment `Predictions on the test set.`** This task is considered passed if your $F_1$ score on the test is larger than 0.7. But we encourage you to try and get larger scores, you can definitely do it:)\n",
    "\n",
    "\n",
    "**Peer Review**\\\n",
    "Some of the tasks cannot be checked automatically,  therefore, we'll be using peer review. Please, download this notebook with solutions (`File → Download as → Notebook (.ipynb)`) and submit it for peer review. Each peer reviewed task contains grading instructions. \n",
    "\n",
    "\n",
    "\n",
    "# Table of Contents:\n",
    "* [Part1.](#part1) Decision Trees\n",
    " - [Task 1](#task1)[1 pt]\n",
    " - [Task 2](#task2)[1 pt]\n",
    " - [Task 3](#task3)[Peer Review]\n",
    "* [Part2.](#part2) Competition! [Peer Review]\n",
    "    \n",
    "\n",
    "## Part 1. Let's train some decision trees. <a class=\"anchor\" id=\"part1\"></a>\n",
    "\n",
    "In this part, we will do the simplest preprocessig of the dataset and train decision trees. In the task, you are supposed to predict whether income of a person exceeds \\$50K/year. The target variable is equal to `1` if a person earns > \\$50k/year and `0` otherwise. \n",
    "\n",
    "As an evaluation criterion, we will be using $F_1$score. As you know, it is a weighted average of precision and recall. We are not using accuracy, because the dataset is imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_years</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  education  education_years      marital_status  \\\n",
       "0   39         State-gov  Bachelors               13       Never-married   \n",
       "1   50  Self-emp-not-inc  Bachelors               13  Married-civ-spouse   \n",
       "2   38           Private    HS-grad                9            Divorced   \n",
       "3   53           Private       11th                7  Married-civ-spouse   \n",
       "4   28           Private  Bachelors               13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital_gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week native_country  target  \n",
       "0             0              40  United-States     0.0  \n",
       "1             0              13  United-States     0.0  \n",
       "2             0              40  United-States     0.0  \n",
       "3             0              40  United-States     0.0  \n",
       "4             0              40           Cuba     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('week5_train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr, val = train_test_split(train_data, test_size=0.4, random_state=42)\n",
    "\n",
    "y_train = tr.target\n",
    "y_valid = val.target\n",
    "X_train = tr.drop(['target'], axis=1)\n",
    "X_valid = val.drop(['target'], axis=1)\n",
    "\n",
    "all_data = pd.read_csv('week5_train.csv')\n",
    "y_all = all_data.target\n",
    "X_all = all_data.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "210b94f03d658eb2f945598cff06fb60",
     "grade": false,
     "grade_id": "cell-cfd6b8c9e0a01674",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task1\"></a>\n",
    "\n",
    "---\n",
    "**Task 1** [1 pt] Create `column_transformer` which has the following steps:\n",
    "- fills all the missing values \n",
    "- encodes all the categorical features using OHE \n",
    "- scales numerical features.\n",
    "\n",
    "P.S. note, that you'll have to import all the required modules yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "523b398e8f35876708b78b5da2b1b7d7",
     "grade": false,
     "grade_id": "cell-72d8346d6028cb1d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "all_col=['workclass','education','marital_status','occupation','relationship','race','sex','native_country','age','education_years','capital_gain','capital_loss','hours_per_week']\n",
    "categ_columns = ['workclass','education','marital_status','occupation','relationship','race','sex','native_country']\n",
    "num_columns=['age','education_years','capital_gain','capital_loss','hours_per_week']\n",
    "\n",
    "\n",
    "\n",
    "# your code here\n",
    "\n",
    "numeric_pipe  = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "categ_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder()\n",
    ")\n",
    "\n",
    "\n",
    "column_transformer=ColumnTransformer([\n",
    "    ('numeric',numeric_pipe,num_columns),\n",
    " ('categ', categ_pipe, categ_columns)\n",
    "],\n",
    "remainder='passthrough'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36c9c5802ffe52fa0a21f3cc0bc41e93",
     "grade": true,
     "grade_id": "cell-183f2ac417f75d76",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_transformed = column_transformer.fit_transform(X_train)\n",
    "X_transformed.shape\n",
    "\n",
    "X_transformed = column_transformer.fit_transform(X_train)\n",
    "assert X_transformed.shape[0] == 19536\n",
    "assert X_transformed.shape[1] == 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0d7f88a9241e795223a173c45a51f03",
     "grade": false,
     "grade_id": "cell-fb4d3801b5f35b11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task2\"></a>\n",
    "\n",
    "---\n",
    "**Task 2** [1 pt] Create a function `tree_pipe`, which given a maximal tree depth returns a pipeline with two steps:\n",
    "\n",
    "1. Column transformer (defined above)\n",
    "2. DecisionTreeClassfier with the required `max_depth` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5642bf74cd64dca208579f4820be58f9",
     "grade": false,
     "grade_id": "cell-b9de0824900552ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def tree_pipe(max_depth):\n",
    "    # your code here\n",
    "    pipeline = make_pipeline(\n",
    "    column_transformer,\n",
    "    DecisionTreeClassifier(max_depth=max_depth)\n",
    "    )\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e60c8560b3230266728aba428e5a9337",
     "grade": true,
     "grade_id": "cell-c542e20f3e709f98",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_pipe = tree_pipe(1)\n",
    "\n",
    "test_pipe = tree_pipe(12)\n",
    "tree = test_pipe.steps[1][1]\n",
    "assert tree.max_depth == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf6de67039590f3d54c06be163f3d152",
     "grade": false,
     "grade_id": "cell-52d80521f0a0cbf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task3\"></a>\n",
    "\n",
    "---\n",
    "**Task 3** [Peer Reviewed] Fit decision trees of different depth (from 1 to 100) using the function from the **task 2**. For each depth calculate $F_1$score on the train and validation datasets. Draw a plot, how both scores depend on the maximal tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8349f434757d72a87b30098e0b7fe48",
     "grade": false,
     "grade_id": "cell-d9d8ea084313b76d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "list_score_predict = []\n",
    "list_score_valid_po_train = []\n",
    "# your code here\n",
    "for depth in range(1,101):\n",
    "    test_pipe = tree_pipe(depth)\n",
    "    test_pipe.fit(X_train,y_train)\n",
    "    y_pred= test_pipe.predict(X_valid)\n",
    "    y_valid_po_train = test_pipe.predict(X_train)\n",
    "    \n",
    "    score_predict = f1_score(y_valid, y_pred)\n",
    "    list_score_predict.append(score_predict)\n",
    "    score_valid_po_train=f1_score(y_train,y_valid_po_train)\n",
    "    list_score_valid_po_train.append(score_valid_po_train)\n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "debe6d9b856784585ebcef9f3363c95f",
     "grade": true,
     "grade_id": "cell-8d7c2fabbc41326a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3hU1b3G8e8ilwkkXANEBIUoCEhFhIgXRIO1FW9QLR6hpz1qbam3Wj311NpjK9ZqPS22ar0Vr9Ve0IpUtFgUJWprVRDlKigKSAQBQSCBkEnCOn/8JskQc5nADJM9836eZ55kZvbsWb/JzLtX1qy9t/PeIyIiwdcu2Q0QEZH4UKCLiKQIBbqISIpQoIuIpAgFuohIilCgi4ikiBYD3Tn3sHNuk3NuaRP3O+fcXc65Vc65xc654fFvpoiItCQzhmUeBe4GHmvi/jOAAZHLccB9kZ/N6t69u+/Xr19MjQTYuXMnubm5MS+fKtKx7nSsGdKz7nSsGfav7rfffvsz732Pxu5rMdC996865/o1s8h44DFveyi94Zzr4pzr5b3f0Nx6+/Xrx4IFC1p6+jolJSUUFxfHvHyqSMe607FmSM+607Fm2L+6nXNrm7ovlh56S3oD66Kul0Zu+0KgO+cmA5MBCgoKKCkpiflJysvLW7V8qkjHutOxZkjPutOxZkhc3fEIdNfIbY0eT8B7Pw2YBlBUVORbs4XSljx9pGPNkJ51p2PNkLi64zHLpRQ4JOp6H2B9HNYrIiKtEI9AnwX8V2S2y/HA9pbGz0VEJP5aHHJxzv0FKAa6O+dKgRuBLADv/f3AbOBMYBWwC7g4UY0VEZGmxTLLZVIL93vgiri1SERE9on2FBURSRHxmOUikhA1NbBtG4TDUFVll927obLSLuGwXSorYccOW3b7dntcLeegXTu7ZGRAZqZdampsXbt37718Mq1Z04+XX052Kw6sdKwZoGPHriRico8CXQ6Y9evho4/qg7i8HDZvhk2b4LPPYMsW2LoVVq8eQXk5bNx4YMLWNTbxNin6JrsBSZCONcOkSV0Ssl4FusTV+vXw0EOwbh107Ah5eVBaCq++CqtWNf24Ll0gPx+6dYMuXcKcdBL06gU9e0IoBFlZ1rPOybHrtZfsbLt06mTr6NzZlgPw3i579tRfqqutpx+9rnZtZOCxpOSVtJuTnY41A5SUrCYRGzMFuuy3cBj+9S+YNg2eesp61T17Wg98507o2hVOPhkuuwy+9CUL0uxs6NDBlsvPt8CuVVKyJC0/5CL7S4EuMdu6FVauhE8/tSGSzZvh9dehpMSCu1Mn+P734fLLoX9/e0xNjfWA286whkjqUqDLF3gP8+fDO+/A0qV2Wb7cxrobGjAALrwQvvIVOO00G2KJlpFxYNosIgp0ibJjB/zhD3DvvbBihd2WlwdDhsDZZ8PgwTBoEPTpY8Mk+fk2bCIibYMCPY15D4sXw9y58PLLNnSyaxeMHAmPPALFxXDooW3nS0MRaZ4CPU299RZcd52FOMDAgXDxxXDRRVBUlMyWici+UqCnmcWL4eabbTZKjx5wxx3w9a/bMIqIBJsCPQ14D3PmwO232/BKbi7ceCP88Ic2V1xEUoMCPYVVV8Nf/wq//CUsWQIHH2y/T55sO/CISGpRoKegHTvgscfgt7+1Xe0HD4ZHH4VJk2yHHhFJTQr0FLJmDUydalMPy8vh+ONtmGXcOM1UEUkHCvQU4D08/jhccYXthj9xIlx5JRx7bLJbJiIHkgI94D7/3I6R8sQTdryUxx6Dvul5ADuRtKd/xANs5kzbi3PGDLj1Vts5SGEukr7UQw+gDRtsSOXpp+Hoo+HZZ2HEiGS3SkSSTYEeMC++aLNVdu6E226D//7vvQ89KyLpS0MuAbFnD9xyC5x+Ohx0kB0J8brrFOYiUk899AD45BP47nfh+efhG9+wE0nk5ia7VSLS1qiH3oZ5D88914sjj7SDaN1zD/zxjwpzEWmceuht1Pr1duKIuXMHMmYMPPAAHH54slslIm2Zeuht0HPPwdChdnq3a65Zydy5CnMRaZkCvQ2proZrroFzzoFDDoGFC2HcuA3abV9EYqKoaCN27bLjkt9xB1x1Fbzxhp10QkQkVhpDbwO2brVe+b//DXffbcdkERFpLQV6ki1bBuefDx9+CE8+CRMmJLtFIhJUGnJJEu/hvvvs/J1bttgZhRTmIrI/FOhJsHMnnHceXH45FBfbeT6Li5PdKhEJOgX6AVZRYSecmDULfvMb+PvfoaAg2a0SkVQQU6A758Y651Y651Y5537cyP2dnXPPOucWOeeWOecujn9Tg6+y0mayzJtnZxW65hqdSUhE4qfFOHHOZQD3AGcARwKTnHNHNljsCmC59/5ooBi43Tmns1dGqa6GCy6w47FMmwbf/GayWyQiqSaW/uFIYJX3/iPvfRiYDoxvsIwHOjrnHJAHbAWq49rSgLv9dnjmGfjd7+A730l2a0QkFcUS6L2BdVHXSyO3RbsbGAysB5YAP/De74lLC1PAqlUwZQqce66dmEJEJBFimYfuGrnNN7h+OvAucCpwOPCic+417/2OvVbk3GRgMkBBQQElJSUxN7S8vLxVy7cV3sO11x5NRkZHvvGNtygpCbfq8UGte3+kY82QnnWnY82QwLq9981egBOAOVHXrweub7DM34HRUddfBkY2t94RI0b41pg3b16rlm8rHnnEe/D+vvv27fFBrXt/pGPN3qdn3elYs/f7VzewwDeRq7EMucwHBjjnCiNfdE4EZjVY5mPgywDOuQJgIPDRfm5rAm/DBvjhD+Gkk2Dy5GS3RkRSXYtDLt77aufclcAcIAN42Hu/zDl3aeT++4GbgUedc0uwIZrrvPefJbDdbV5ZGZx9NuzebbNaND1RRBItpmO5eO9nA7Mb3HZ/1O/rga/Gt2nBVVVlx2dZtMh2IBo8ONktEpF0oINzxZn3dv7POXPgwQfhzDOT3SIRSRcaCIizBx6wvUCnTIFLLkl2a0QknSjQ46isDH76Uxg9Gn72s2S3RkTSjYZc4uj222HTJhs3d43N3hcRSSD10ONkwwaYOtW+DD3uuGS3RkTSkQI9Tm66yY6meOutyW6JiKQrBXorbNliJ6No6M03bUbLZZdB//4Hvl0iIqBAj9lbb8HQoXD00TYVccECC/grroATT4Tu3e0LURGRZFGgx+Cxx+DkkyE720L7zTfh2GOhb1/4/e/tVHLLlkGPHsluqYikM81yacEdd9iZhU49FZ54wnri114Ld94J778P110HX/pSslspIqJAb9E991jvfM4cyIy8Wp06aXhFRNoeDbk0Y9Uqu/zHf9SHuYhIW6VAb8bzz9vPM85IbjtERGKhQG/G88/DEUfAYYcluyUiIi1ToDehogLmzVPvXESCQ4HehFdesZNTjB2b7JaIiMRGgd6E2bMhJwdOOSXZLRERiY3mbjTh+edhzBho//A98NBDNgG9e3f4ylfg4ouT3TwRkS9QD70RtdMVzxjr4bbb4LPPYMcOePVV+Pa34d//TnYTRUS+QIHeiLrpin2WQGkp3HwzvPEGrFgBvXrZrqN79iS3kSIiDSjQG3jhBTtRRf/+0H/BdMjIgHPOsTvz8uCXv7SDufzlL8ltqIhIAwr0iI8+gvHj4fTTba/Qhx8GZs60b0W7datf8FvfghEj7CAuO3fG/gTvvQeTJtnlssvsHHWrV8e9DhFJXwp0bCRl5Eh4+WUbMl+2DEb3WGF3nHvu3gu3a2dH7PrkE/j1r7+4sk8/hbvugjVr6m+bMcOe4B//gLffhqeegltugSFD7AmrqhJan4ikh7QP9HXr4KtftV75woXW8Q6FsN45wNe+9sUHnXSSHeDl1lvt+Lm1Vq6EE06AH/zAdi89/XT43vdgwgQL7yVL7BCNmzfD2rU2yf3662H4cNuLSURkP6RdoC9dWn9yii1bLHO3b7fO84ABUQvOnGm96j59Gl/R738PX/4yXHopTJ5sM2BGjbJhmOeegxtvtGGWadMs1F95Ze919ekDTz8NzzxjM2hOPdXG6t97L6H1i0jqSptAX77cxsiPOspOTtG9OxQU2Nj5rFkwbFjUwqWlMH/+F4dbonXpYsF9/fXwwAM21t65M7z+Opx1lgX66tW2rvvvj3T7GzFunA3t3HabbRSOOsr+K/jzn6GsLK6vgYiktpTdsejjj+Gdd+CDD2zY+sknbZLKL35hox+rV9twy7hxcMqw7fDwDNi6Ffr1swdA84EONgPm1lvtS9IZM+C3v7WtRPT9vXu33Nj27W2s55JL4Fe/sjB/5hnIyeGI006DQYPgoIP2+bUQkfSQkoH+1ls2zF37XWP37vD97+zihq730v33d1lveeRIC+KH3rEwrqjYeyVHHgkDB8b2hF//ul32V/fuFui33WY7Lz3+OAc9+KCNBV13HRQV2UD/woWwfr0N75SX2yEhf/Ur692LSNpKuUCvrobJkz098ip4+tw/ckTWarpu/RD+MAsqK+0b0NxcG9P+859tmOSii2x3/gED7MvKNWtg8ODkFdGunY3HjxrF/JNO4riZM/c+RdLhh0NhIfTsab37F16wMaPLL4ebbtp7mqWIpI2UC/Q774RFixwz+CbHPTzTzhfXuTNceCFcffXeQb1xo93fvn39bV26wNFHH/iGN6GiTx/7D2LhQvvy9JhjrJ5oW7bYvPZ777WN1E9/auGenZ2cRotIUqRUoK9dCz+7YQ9nu+c598wqeKbaxrGbEj3e3dYNH970ffn5dvLT730PfvhDOzTB3XfbmPzmzfYfh3P2BW5RUf3jFi2yL3aHDoXRo21j5r19ubBqlT0mJ8c2DFu3woYNdlybUaNsyMq5hJctIrFLmUD3Hq68rAYqK7m7+xTcI7ObD/NUNHSoDb/MmQP/8z/wk59Ahw72Re/GjTZN8pvfhP/8T+vNP/ts/WOds+Md1I7Nt2TECPsvoLDQNhqbN9s6Ona0S+fONvTTtasd/yYrKzE1ew/btlmbq6rs0rOnbZxisXWrzSY66KD6mUg7dti35lu31i/XqZO9vk3VsWGDbSBHjbL6W6u62mqJVThsG96KCjtwf6dONmTY2o2s97Bpk31/k+jPy549dkyktWutAxE9jXfPHps/3KVLfQ01NfDhh7b8CSfYrIbaNs+cacfo6NnT1jV6tH2HlJNTv8ySJfZ5CIehb1+79Opl78nOnW2ZLVusk5KdbUOZ7RpM/PPeXuMdO6w9Bx1U/zpt2GAdojfftM/BsGH2GVq+3Ga7vfuu3XbeeXDccV9cdwLEFOjOubHAnUAG8KD3/rZGlikG7gCygM+89wf0SOJvvw3PPZ/B/zGFvn+6FXr0OJBP33Y4ZzssffWrFnRdu9pt27fbl62//S388Y8Wtj//OXz3u7azU0mJvQHPOMO+EB4wwN6Au3fbdw/dutmHoWNH2zDU/gcQi9xcKC62Ng0cCJ9/bh+kTz6xKZsrV1r7hgyBoUM5uLrapiiVl1sNtd9rfPqpfeALCuznunXW9u3bv/icXbrYhmzgQFvvkCE2tLZzpwX4okW2M9fixfWP6dbNPsCff954HR06wPHH2385nTtbXWVl9R9qsOcYP94+xLt22XSrtWttA1E7tapTJzj4YAuH7dvtto0bOSE/3/52p55qO6ZlZVnQ5OTYc+fmWrunT7e/QcO6DzvMpm2NHl2/4dm2zXa8eOstm6NbWGh/3969bV1vvGEb45wce42OOspet4MPtpBfudLC6c037fm8t/DNyLANYHZ2fTuzsqy2ggK7dOtmbc7Ntddg5kz7G9YaOJAhPXvaa7hypQVndrY9d+fO9retnayQlwcXXGA7jvzud/Daa/Ye3bgR/va3+vd+374WzCtW2PurKbUbjeiNaJcuFry9e9vf6sMPbR01NfXLZGXZ69Ohg71+tY/btm3v9YdCNjvtzjth6lT7Ww8ebLnUowfdeve2z0ScOd9Cr8A5lwG8D3wFKAXmA5O898ujlukCvA6M9d5/7Jzr6b3f1Nx6i4qK/IIFC2JuaElJCcXNvAC3XrWB//1dLzZddiM97r0p5vW2dS3V3Wpr19oMmrPO2reeZC3v7UNeUWFv0u7d7UNSVma9me3brYe7dattKF580eaQRsvMtB7NwIEWBMuW2aWysn6Z9u3tQ1pYaB+KbdvsQ7x1q/XwBgywD3CnThYGGRkWGmvWWICtWNH4MXPat7fedHGxhc+nn9p/J2DP1a+f1VX7wd+4Ef75TwuSpUutR12rqMhCfPhwC/cnn7QNVq2CAltfYSEceqhtqNavt+fs3NnqOPhgNr32Gj2XLbOAbU7HjjaldswYC8v27W1/h2efhZde2vv1AwufESPstVq92nqQGzfa7KgTTrDvjEpLbeO2bJm1KzoXBg605Xr2tI28cxZy4bA9V+1/RuGw/d03brR1fP65bdRq23DmmbahO+IIm5Qwdy67Fi+mw1FHWdj16WP/LZSW2mOPOMLaVlBgh8t44gnbIPfsaZ2RSy6x99D69fCvf1ldK1facGHfvtY5GTvWXuPaDeumTbbu2v++IgFLebm9n99809pfWGjvq0MPtcd37Gi1176vtm611/+cc2wjWFZmr98HH1iQDx9uob59O/z97/a3Wbeu7r/ZNeecQ78//KH5v3MTnHNve++LGr0vhkA/AZjivT89cv16AO/9L6OWuRw42Ht/Q6yNinegn9p/LZ9/uJV3PimwLXyKiHugJ9Pq1fbh69bNLvn59oGMVl3N6888w4mnnWZh1fD+fbFzpwV7VZX19HJz7T3S1M5eLfHewqt2aKrhrKJw2L7Ezs+HQw6pHwZoQUlJCcWnnFIfuLUhuXu3BePOndbusWObXmdtrbXat7dgbPg6hsNNf2leVVUfyv362cZ6X+3ZY+3PzGz0+Vr1/i4vt+A+4QTbgAdYybx5FI8Zs0+PbS7QY/m09AbWRV0vBY5rsMwRQJZzrgToCNzpvX9sH9q6T3btgn991IsfdJsLB8c4DCAHXmGhXZqTmUk4P/+LM3n2R26u9VDjxTnbGDS1QcjOtqGZfV137RDRvoi11uZmQGVlWW+5qcNetEa7dtY7j4e8PBtySQUJmlAQS6A39swNu/WZwAjgy0B74N/OuTe89+/vtSLnJgOTAQoKCigpKYm5oeXl5U0uP//fnQj74Rw9qLRV6wyC5upOVelYM6Rn3elYMySu7lgCvRQ4JOp6H2B9I8t85r3fCex0zr0KHI2Nvdfx3k8DpoENubRmKKG5f83+/vt1ZFPJuVcNp0OqDE9EpNSQS4zSsWZIz7rTsWZIXN2xzKOZDwxwzhU657KBicCsBss8A4x2zmU65zpgQzIH7LCBL87L5CT+SYfTRx+opxQRaXNaDHTvfTVwJTAHC+knvffLnHOXOucujSzzHvAPYDHwFja1cWniml1v0yZYtLEXp/VeEfvcYxGRFBTTFALv/WxgdoPb7m9w/ddAI6fwSayX/14BtOe00w70M4uItC2B31P0xb98RldyGf6NQcluiohIUgX6BBfew4tv5HFquxIyRp+Y7OaIiCRVoAN91SpYV9aVrwxYu/cRE0VE0lCgA331O3b8hC+dkp/kloiIJF+gA73y/bUAhI45MsktERFJvmAH+k47QFKoc2zHyhARSWXBDvSKPQCEcgM/WUdEZL8p0EVEUkRqBHpHnTtTRCTQgR7eHQn0vASd3kxEJEACHeiVlXYUX/XQRUSCHui77Wd2x30884yISAoJdqBXQjtqyMxVoIuIBD7QQ1TG57yTIiIBF+xAD0cCPUHn5xMRCZKAB7oj5MLJboaISJsQ6EAPK9BFROoEOtArq9qR3a462c0QEWkTgh3o1e0ItatKdjNERNqEYAd6VYYCXUQkItiBXt2OUIaGXEREIPCBnqlAFxGJCHSgh2vaEcqoSXYzRETahEAHemVNJqFMBbqICAQ+0LPIztyT7GaIiLQJwQ70PZmEstRDFxGBwAd6FqEs9dBFRCDoge6zCWX5ZDdDRKRNCH6gZ6uHLiICAQ/0sM8ipLPPiYgAAQ5076GSHLIV6CIiQIADvSocOUG0zj4nIgLEGOjOubHOuZXOuVXOuR83s9yxzrka59yE+DWxcZXldlAuBbqIiGkx0J1zGcA9wBnAkcAk59yRTSz3f8CceDeyMZVldmILBbqIiImlhz4SWOW9/8h7HwamA+MbWe77wAxgUxzb16S6QM/R+URFRCC2QO8NrIu6Xhq5rY5zrjdwLnB//JrWvLpAb69AFxEByIxhmcYSs+HePHcA13nva5xrOmCdc5OByQAFBQWUlJTE2EwoLy/fa/lPF5QDZ/PZlg2tWk/QNKw7HaRjzZCedadjzZC4umMJ9FLgkKjrfYD1DZYpAqZHwrw7cKZzrtp7/7fohbz304BpAEVFRb64uDjmhpaUlBC9/KLPPwKgsP+hFBefFPN6gqZh3ekgHWuG9Kw7HWuGxNUdS6DPBwY45wqBT4CJwDeiF/DeF9b+7px7FHiuYZjHW+VOO7FFqH1gZ16KiMRVi4Huva92zl2JzV7JAB723i9zzl0auf+AjZtHqwv0DhnJeHoRkTYnlh463vvZwOwGtzUa5N77i/a/WS2rC/TcmEoQEUl5gR2vqNxlx0FXD11ExAQ20MMVkUBXD11EBAhwoNf20LNzs5LcEhGRtiG4gV5hx0EP5SnQRUQgyIG+O3K0RQ25iIgAgQ70SA+9ow6ILiICgQ70SA9dQy4iIkCgA91+hjrp+LkiIhDgQA9XWg89K0+BLiICAQ70yjBkU4nL0peiIiIQ5ECvdISohGYO1ysikk6CG+hhR8iFk90MEZE2Q4EuIpIighvoVe0IuapkN0NEpM0IbKCHqxyhdgp0EZFagQ30yup2ZGdUJ7sZIiJtRoADPYNQOwW6iEitYAd6hoZcRERqBTfQazIJZdQkuxkiIm1GcAO9OpNQpgJdRKRWcAN9jwJdRCRaYAM9vCeT7Kw9yW6GiEibEdhAr9yTRUiBLiJSR4EuIpIighvoPptQtk92M0RE2gwFuohIighuoBMipPNDi4jUCWSgV1d59pBBSGefExGpE8hAD5fbcdCzFegiInUCGeiVOyoBCIV0+jkRkVrBDPRyOyiXhlxEROoFO9DbB7L5IiIJEchErAv0HA25iIjUiinQnXNjnXMrnXOrnHM/buT+/3TOLY5cXnfOHR3/ptarC/QOgdweiYgkRIuJ6JzLAO4BzgCOBCY5545ssNhq4BTv/VDgZmBavBsaLbzTAj07JyORTyMiEiixdHFHAqu89x9578PAdGB89ALe+9e9959Hrr4B9IlvM/dWudNOPRfqoEAXEamVGcMyvYF1UddLgeOaWf4S4PnG7nDOTQYmAxQUFFBSUhJbK4Hy8vK65d9ftAUYwrr1qykp2RXzOoIouu50kY41Q3rWnY41Q+LqjiXQG/vmsdGDqDjnxmCBflJj93vvpxEZjikqKvLFxcWxtRIoKSmhdvndry8EYMjRgzihOKHD9UkXXXe6SMeaIT3rTseaIXF1xxLopcAhUdf7AOsbLuScGwo8CJzhvd8Sn+Y1rnKXnakolBtL80VE0kMsY+jzgQHOuULnXDYwEZgVvYBz7lDgaeBb3vv349/MvVVWKNBFRBpqMRG999XOuSuBOUAG8LD3fplz7tLI/fcDPwPygXudcwDV3vuiRDW6cped2CKUl5WopxARCZyYurje+9nA7Aa33R/1+3eA78S3aU0L77ZAz85VoIuI1ArknjmVu+07WfXQRUTqBTvQO+oMFyIitYIZ6JUKdBGRhoIZ6LvtZ6iTjp8rIlIrmIFeCZlU0S5b0xZFRGoFMtDDYcgmDE6HzxURqRXIQK8MO0IunOxmiIi0KYEcs1Cgi7QtVVVVlJaWsnv37lY9rnPnzrz33nsJalXbFUvdOTk59OnTh6ys2KdnBzPQq9op0EXakNLSUjp27Ei/fv1wrRgKLSsro2PHjglsWdvUUt3ee7Zs2UJpaSmFhYUxrzeYQy5V7Qi1q0p2M0QkYvfu3eTn57cqzKVpzjny8/Nb/R9PgAO9OtnNEJEoCvP42pfXM5iBXp1BKEM9dBGRaIEM9HBNO7IzapLdDBFpI4qLi5kzZ85et91xxx1cfvnlTS6/YMECAM4880y2bdv2hWWmTJnC1KlTm33ev/3tbyxfvrzu+s9+9jPmzp3b2ubHTSAD3XroGnIRETNp0iSmT5++123Tp09n0qRJLT529uzZdOnSZZ+et2Gg//znP+e0007bp3XFQzBnudRkkpelWS4ibdLVV8O778a0aPuaGsiI4WTvw4bBHXc0efeECRO44YYbqKysJBQKsWbNGtavX8+f//xnrrnmGioqKpgwYQI33XTTFx7br18/FixYQPfu3bnlllt47LHHOOSQQ+jRowcjRowA4IEHHmDatGmEw2H69+/P448/zrvvvsusWbN45ZVX+MUvfsGMGTO4+eabOfvss5kwYQIvvfQS1157LdXV1Rx77LHcd999hEIh+vXrx8SJE3nhhReoqqrir3/9K4MGDYrp9WpJMHvoNVmEMjXkIiImPz+fkSNH8o9//AOw3vkFF1zALbfcwoIFC1i8eDGvvPIKixcvbnIdb7/9NtOnT+edd97h6aefZv78+XX3nXfeecyfP59FixYxePBgHnroIU488UTGjRvHr3/9a959910OP/zwuuV3797NRRddxBNPPMGSJUuorq7mvvvu26u9Cxcu5LLLLmtxWKc1gtlD35NJKGtPspshIo1ppifdUEUc56HXDruMHz+e6dOn8/DDD/Pkk08ybdo0qqur2bBhA8uXL2fo0KGNPv61117j3HPPpUOHDgCMGzeu7r6lS5dyww03sG3bNsrLyzn99NObbcvKlSspLCzkiCOOAODCCy/knnvu4eqrr95r3SNGjODpp5/e79prBbOHvieLUJZ66CJS72tf+xovvfQSCxcupKKigq5duzJ16lReeuklFi9ezFlnndXivO6mpgpedNFF3H333SxZsoQbb7yxxfV475u9PxSyI8VmZGRQXR2/7wMDG+jZWc2/YCKSXvLy8iguLubb3/42kyZNYseOHeTm5tK5c2c2bvPfmM4AAAivSURBVNzI888/3+zjTz75ZGbOnElFRQVlZWU8++yzdfeVlZXRq1cvqqqq+NOf/lR3e8eOHSkrK/vCugYNGsSaNWtYtWoVAI8//jinnHJKnCptWiCHXMI+i5ACXUQamDRpEueddx7Tp09n0KBBHHPMMQwZMoTDDjuMUaNGNfvY4cOHc8EFFzBs2DD69u3L6NGj6+67+eabOe644+jbty9HHXVUXYhPnDiR7373u9x111089dRTdcvn5OTwyCOPcP7559d9KXrppZcmpuho3vukXEaMGOFbY968eXW/57HDX3PMvCaXTSXRdaeLdKzZ+2DXvXz58n163I4dO+LckmCIte7GXldggW8iV4M55EKIUEg9dBGRaIEL9D01niqyCel0oiIiewlcoIfLbYeiUE6SGyIi0sYELtArd1QCEArpyG4iItECF+i1PfRsBbqIyF4CF+iV5XbY3FCOAl1EJFrwAr0sMobeXoEuImbLli0MGzaMYcOGcdBBB9G7d++66+Fw8wfyW7BgAVddddUBamliBW7HosqdtptsqH3gtkUikiD5+fm8GznC45QpU8jLy+Paa6+tu7+6uprMzMbjrqioiKKiogPSzkQLcKDHcMhNETngWnH0XGpq2sfj6LmNuuiii+jWrRvvvPNO3V6gV199NRUVFbRv355HHnmEgQMHUlJSwtSpU3nuueeYMmUKH3/8MR999BEff/wxV199daB678EN9A4KdBFp3vvvv8/cuXPJyMhgx44dvPrqq2RmZjJ37lx+8pOfMGPGjC88ZsWKFcybN4+ysjIGDhzIZZddRlZWVhJa33qBDfRs9dBF2qTW9KTLyiridvjcxpx//vlkRP4F2L59OxdeeCEffPABzjmqqho/L/FZZ51FKBQiFArRs2dPNm7cSJ8+fRLWxniKaSDaOTfWObfSObfKOffjRu53zrm7Ivcvds4Nj39TTXhXpIeeG7htkYgcYLm5uXW///SnP2XMmDEsXbqUZ599tslD4NYe2hbif3jbRGsx0J1zGcA9wBnAkcAk59yRDRY7AxgQuUwG7iNBKnfZcdAV6CLSGtu3b6d3794APProo8ltTILE0kMfCazy3n/kvQ8D04HxDZYZDzwWORjYG0AX51yvOLcVgMoKBbqItN6PfvQjrr/+ekaNGkVNTWqeIMf5Fs6s4ZybAIz13n8ncv1bwHHe+yujlnkOuM17/8/I9ZeA67z3CxqsazLWg6egoGBEw7N0N6e8vJy8vDxWz/qMmY9355Kby+k8KC/mxwdVbd3pJB1rhmDX3blzZ/r379/qx9XU1NSNcaeTWOtetWoV27dv3+u2MWPGvO29b3SeZSzd3Mb24Gm4FYhlGbz304BpAEVFRb64uDiGpzclJSUUFxdTXAwX/ybmhwVebd3pJB1rhmDX/d577+3Tl5tlcTynaJDEWndOTg7HHHNMzOuNZcilFDgk6nofYP0+LCMiIgkUS6DPBwY45wqdc9nARGBWg2VmAf8Vme1yPLDde78hzm0VkTaspeFbaZ19eT1bHHLx3lc7564E5gAZwMPe+2XOuUsj998PzAbOBFYBu4CLW90SEQmsnJwctmzZQn5+Ps7pOEv7y3vPli1byMlp3YkfYpoq4r2fjYV29G33R/3ugSta9cwikjL69OlDaWkpmzdvbtXjdu/e3erQSgWx1J2Tk9PqHZo0909E9ltWVhaFhYWtflxJSUmrvvRLFYmqW4csFBFJEQp0EZEUoUAXEUkRLe4pmrAndm4zsLYVD+kOfJag5rRl6Vh3OtYM6Vl3OtYM+1d3X+99j8buSFqgt5ZzbkFTu7umsnSsOx1rhvSsOx1rhsTVrSEXEZEUoUAXEUkRQQr0acluQJKkY93pWDOkZ93pWDMkqO7AjKGLiEjzgtRDFxGRZijQRURSRCACvaWTVKcC59whzrl5zrn3nHPLnHM/iNzezTn3onPug8jPrslua7w55zKcc+9EznyVLjV3cc495ZxbEfmbn5AmdV8TeX8vdc79xTmXk2p1O+ceds5tcs4tjbqtyRqdc9dHsm2lc+70/XnuNh/oMZ6kOhVUAz/03g8GjgeuiNT5Y+Al7/0A4KXI9VTzA+C9qOvpUPOdwD+894OAo7H6U7pu51xv4CqgyHv/Jexw3BNJvbofBcY2uK3RGiOf8YnAkMhj7o1k3j5p84FObCepDjzv/Qbv/cLI72XYB7w3VusfIov9AfhaclqYGM65PsBZwINRN6d6zZ2Ak4GHALz3Ye/9NlK87ohMoL1zLhPogJ3ZLKXq9t6/CmxtcHNTNY4HpnvvK733q7FzSozc1+cOQqD3BtZFXS+N3JaynHP9gGOAN4GC2rM/RX72TF7LEuIO4EfAnqjbUr3mw4DNwCORoaYHnXO5pHjd3vtPgKnAx8AG7MxmL5DidUc0VWNc8y0IgR7TCahThXMuD5gBXO2935Hs9iSSc+5sYJP3/u1kt+UAywSGA/d5748BdhL8YYYWRcaNxwOFwMFArnPum8ltVdLFNd+CEOhpcwJq51wWFuZ/8t4/Hbl5o3OuV+T+XsCmZLUvAUYB45xza7ChtFOdc38ktWsGe0+Xeu/fjFx/Cgv4VK/7NGC1936z974KeBo4kdSvG5quMa75FoRAj+Uk1YHn7ESMDwHvee9/E3XXLODCyO8XAs8c6LYlivf+eu99H+99P+zv+rL3/pukcM0A3vtPgXXOuYGRm74MLCfF68aGWo53znWIvN+/jH1XlOp1Q9M1zgImOudCzrlCYADw1j4/i/e+zV+wE1C/D3wI/G+y25OgGk/C/tVaDLwbuZwJ5GPfin8Q+dkt2W1NUP3FwHOR31O+ZmAYsCDy9/4b0DVN6r4JWAEsBR4HQqlWN/AX7DuCKqwHfklzNQL/G8m2lcAZ+/Pc2vVfRCRFBGHIRUREYqBAFxFJEQp0EZEUoUAXEUkRCnQRkRShQBcRSREKdBGRFPH/b87LYGL5+DUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depth = range(1,101)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(depth, list_score_predict, color = 'r', label = 'Validation')\n",
    "ax.plot(depth, list_score_valid_po_train, color = 'b', label = 'Train')\n",
    "ax.grid(True)\n",
    "ax.legend(loc='upper_right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Peer Review Grading.** Please check that the plot above is correct (below you can see the correct answer).\n",
    "\n",
    "<img src=\"Correct_f1.png\" width=400 height=400 />\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Let's compete. <a class=\"anchor\" id=\"part2\"></a>\n",
    "\n",
    "In this second part of the assignment your task will be straightforward: achieve the best possible score on the test set. To make everything fair, we will be using [Kaggle competition](https://www.kaggle.com/c/predict-income-group). \n",
    "\n",
    "At this stage you are free to use any models or preprocessing methods you want. You can use assignemnts from the previous weeks as an inspiration!\n",
    "\n",
    "Below you can see how the test dataset can be loaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_years</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass     education  education_years      marital_status  \\\n",
       "0   25    Private          11th                7       Never-married   \n",
       "1   38    Private       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  Some-college               10  Married-civ-spouse   \n",
       "4   18        NaN  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital_gain  capital_loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                NaN    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours_per_week native_country  \n",
       "0              40  United-States  \n",
       "1              50  United-States  \n",
       "2              40  United-States  \n",
       "3              40  United-States  \n",
       "4              30  United-States  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('week5_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we do not restrict you a lot in this task, we still ask you to stick to the following steps, which will be graded by your peers\n",
    "\n",
    "**Peer Review Grading.** Below you will find the list of criteria for peer review:\n",
    "1. Consider categorical features. Show which feature are categorical, check if all the categories are reasonable. Provide plots.\n",
    "2. Consider numerical features\n",
    "3. Fill missing values. \n",
    "4. Explore different hyperparameters of the decision trees (not only `max_depth`)\n",
    "5. Choose the best model using cross-validation or just validation\n",
    "6. Make a prediction on the test set.\n",
    "7. Try to make your code readable. Do not forget to leave comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PREPROCESSING AND MODELS HERE\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "categ_columns = ['workclass','education','marital_status','occupation','relationship','race','sex','native_country']\n",
    "num_columns=['age','education_years','capital_gain','capital_loss','hours_per_week']\n",
    "numeric_pipe  = make_pipeline(\n",
    "    SimpleImputer(),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "categ_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(handle_unknown='ignore')\n",
    ")\n",
    "\n",
    "\n",
    "column_transformer=ColumnTransformer([\n",
    "    ('numeric',numeric_pipe,num_columns),\n",
    " ('categ', categ_pipe, categ_columns)\n",
    "],\n",
    "remainder='passthrough'\n",
    ")\n",
    "\n",
    "\n",
    "def tree_pipe(max_depth):\n",
    "    # your code here\n",
    "    pipeline = make_pipeline(\n",
    "        column_transformer,\n",
    "        DecisionTreeClassifier(max_depth=max_depth,  ccp_alpha=0.0000000002, min_samples_leaf=5, min_impurity_split=0.0000000000000000005,min_samples_split=0.000005, max_leaf_nodes=117)\n",
    "    )\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def forest_pipe():\n",
    "    # your code here\n",
    "    pipeline = make_pipeline(\n",
    "        column_transformer,\n",
    "        RandomForestClassifier(n_estimators=150, max_depth=10,min_samples_leaf=3)\n",
    "    )\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def grad_pipe():\n",
    "    # your code here\n",
    "    pipeline = make_pipeline(\n",
    "        column_transformer,\n",
    "        GradientBoostingClassifier(loss='exponential',n_estimators=1000,learning_rate=0.2, criterion='mae')\n",
    "    )\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "grad=grad_pipe()\n",
    "forest = forest_pipe()\n",
    "test_tree = tree_pipe(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6939175931981687"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tree_pipe_f1\n",
    "test_tree.fit(X_train, y_train)\n",
    "y_pred= test_tree.predict(X_valid)\n",
    "y_valid_po_train = test_tree.predict(X_train)\n",
    "    \n",
    "score_predict_tree = f1_score(y_valid, y_pred)\n",
    "score_predict_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6482732732732733"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forest_pipe_f1\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred= forest.predict(X_valid)\n",
    "y_valid_po_train = forest.predict(X_train)\n",
    "    \n",
    "score_predict_forest = f1_score(y_valid, y_pred)\n",
    "score_predict_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bac1f232acad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#grad_pipe_f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_valid_po_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1245\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#grad_pipe_f1\n",
    "grad.fit(X_train, y_train)\n",
    "y_pred= grad.predict(X_valid)\n",
    "y_valid_po_train = grad.predict(X_train)\n",
    "    \n",
    "score_predict_grad = f1_score(y_valid, y_pred)\n",
    "score_predict_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='mean',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   Standa...\n",
       "                                   verbose=False)),\n",
       "                ('decisiontreeclassifier',\n",
       "                 DecisionTreeClassifier(ccp_alpha=5e-05, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features=None, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort='deprecated', random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tried gridsearch for decision tree but did not worked well\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# your code here\n",
    "param_grid = [\n",
    "    {\n",
    "        \"decisiontreeclassifier\": [DecisionTreeClassifier()],\n",
    "        'decisiontreeclassifier__ccp_alpha': [0.00000002,0.000000002,0.000000000000000000000002,0.0000000000000000000000000000002,0.005,0.00005,0.000005],\n",
    "        #\"decisiontreeclassifier__min_impurity_split\": [0.00000002,0.000000002,0.000000000000000000000002,0.0000000000000000000000000000002, 0.005,0.00005,0.000005],\n",
    "        #\"decisiontreeclassifier__min_samples_split\": [0.00000002,0.000000002,0.000000000000000000000002,0.0000000000000000000000000000002, 0.005,0.00005,0.000005],\n",
    "        #\"decisiontreeclassifier__max_features\": ['auto', 'sqrt', 'log2','None'],\n",
    "        #\"decisiontreeclassifier__max_leaf_nodes\": [1,2,3,4,5,6,7,8]\n",
    "        \n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "grid_pipe = GridSearchCV(tree_pipe(10), param_grid=param_grid, cv=5, scoring='f1')\n",
    "grid_pipe\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "grid_pipe.best_estimator_\n",
    "grid_pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction\n",
       "Id               \n",
       "0           False\n",
       "1           False\n",
       "2           False\n",
       "3            True\n",
       "4           False\n",
       "...           ...\n",
       "16276       False\n",
       "16277       False\n",
       "16278        True\n",
       "16279       False\n",
       "16280        True\n",
       "\n",
       "[16281 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = grid_pipe.predict(test_data)\n",
    "# pd.DataFrame({'Prediction': preds}).to_csv('my_prediction.csv')\n",
    "\n",
    "df = pd.DataFrame({'Prediction': preds})\n",
    "df.index.name = 'Id'\n",
    "df['Prediction'] = df['Prediction'].apply(lambda x: bool(x))\n",
    "display(df)\n",
    "df.to_csv('my_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not forget to save your predictions on test and submit them on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see, how `csv` file with the prediction can be created and saved. This file can be later used to upload to Kaggle. Please note, that type of the prediction should be `integer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prediction = np.ones(test_data.shape[0], dtype=int)\n",
    "pd.DataFrame({'Prediction': sample_prediction}).to_csv('my_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not forget to submit your best prediction to the `Predictions on the test set.` programming assignment!\n",
    "\n",
    "This file will be saved to \n",
    "\n",
    "1. Click the Jupyter logo on the top left corner, which will take you to the file tree view.\n",
    "2. Go to the `release/week5` folder, the file `'my_prediction.csv'` should already be there. If not, make sure that you've ran the cell above.\n",
    "3. When you select this file using a tick box, the bottomn `Download` will appear on the top panel. Use it to download the file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
