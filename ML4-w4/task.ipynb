{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgiL_yKL3lDK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97f335734d7422c1790629940a208554",
     "grade": false,
     "grade_id": "cell-06a28f034c84a96d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is programming assignment for week 4. In this assignment you will be solving classification task and performing exploratory data analysis. \n",
    "\n",
    "### Grading\n",
    "The assignment contains both automatically graded and peer reviewed tasks. \n",
    "\n",
    "**Automatic grading**\n",
    "After you finish solving all the tasks restart the kernel (`kernel -> restart`) and and click button `Validate` to check that everything works as expected. Afterwards, you can submit your work.\n",
    "\n",
    "**Peer Review**\n",
    "Some of the tasks cannot be checked automatically,  therefore, we'll be using peer review. Please, download this notebook with solutions (`File → Download as → Notebook (.ipynb)`) and submit it for peer review. Each peer reviewed task contains grading instructions. \n",
    "\n",
    "\n",
    "# Table of Contents:\n",
    "* [Part1.](#part1) EDA and Feature Engineering\n",
    "    - [Explore the Target Variable](#target)\n",
    "    - [Categorical Features](#cat_features)\n",
    "        - [Task 1](#task1) [2 pts]\n",
    "        - [Task 2](#task2) [1 pt]\n",
    "        - [Task 3](#task3) [1 pt]\n",
    "        - [Task 4](#task4) [1 pt]\n",
    "        - [Task 5](#task5) [peer review]\n",
    "    - [Ordinal and numeric features](#rest_features)\n",
    "        - [Task 6](#task6) [peer review]\n",
    "        - [Task 7](#task7) [1 pt]\n",
    "        - [Task 8](#task8) [peer review]\n",
    "        - [Task 9](#task9) [1 pt]\n",
    "    - [Missing values](#na)\n",
    "        - [Task 10](#task10) [1 pt]\n",
    "        - [Task 11](#task11) [2 pts]\n",
    "    - [Columns transformers](#columns)\n",
    "        - [Task 12](#task12) [2 pts]\n",
    "    - [Train-test split](#train_test)\n",
    "* [Part2](#part2). Training, comparing and testing models\n",
    "    - [Task 13](#task13) [1 pt]\n",
    "    - [Task 14](#task14) [1 pt]\n",
    "    - [Task 15](#task15) [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "GMf9yLqu-N-N",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "267fed599d5d6c7c31967dc335741cb1",
     "grade": false,
     "grade_id": "cell-af93d1d8ec998e33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1. Exploratory Data Analysis (EDA) and Feature Engineering <a class=\"anchor\" id=\"part1\"></a>\n",
    "\n",
    "\n",
    "### The goal\n",
    "Explore the data, fix NAs, check if there are some mistakes and outliers, preprocess and select relevant features before fitting the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "Kts8synQs37y",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6cd75eb3dc1214b9b8416a4c4f36eeca",
     "grade": false,
     "grade_id": "cell-b3397408a1f2c9ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0. Explore the dataset and the task\n",
    "\n",
    "Below you can find the dataset, which you will be working with in this assignment. It contains information about the passangers of the Titanic. The target variable that we are going to predict is `Survived`. It is a binary variable which indicates whether a given passenger survived in the Titanic catastroph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1588940435271,
     "user": {
      "displayName": "Anna Kuzina",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiemaXGZADupTQf2gOFyfVMKD8BYzFXipMt2krfaeg=s64",
      "userId": "14976976853760262600"
     },
     "user_tz": -180
    },
    "id": "fzy6pMGbHriu",
    "outputId": "13a5b916-53c8-4950-8c2a-19f488d30f16"
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "oB4Yts808Zy0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b157aeb0c038b4409929e8dd3ca57f80",
     "grade": false,
     "grade_id": "cell-2bb77c57b5e35580",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have data for Titanic passengers, the goal is to predict the column `Survived`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "0J9rbBfC-oXz",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "86b898f53d69b1308154d7d39644048f",
     "grade": false,
     "grade_id": "cell-43979b891da25a75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1 Explore the target <a class=\"anchor\" id=\"target\"></a>\n",
    "\n",
    "To begin with, let us plot the barplot for the traget variable. It is very convenient to use wrapper around `matplotlib` provided by `pandas`. You can read about it [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#cookbook-plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1588941164772,
     "user": {
      "displayName": "Anna Kuzina",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiemaXGZADupTQf2gOFyfVMKD8BYzFXipMt2krfaeg=s64",
      "userId": "14976976853760262600"
     },
     "user_tz": -180
    },
    "id": "KbjWspnu_bjZ",
    "outputId": "0ee65d2c-481c-49c3-e9ea-94de6ded4155"
   },
   "outputs": [],
   "source": [
    "titanic.Survived.value_counts().plot(kind='bar')\n",
    "plt.grid()\n",
    "plt.title('Distirbution of the target variable');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "792236382b32831f7995e9759bd5bd5c",
     "grade": false,
     "grade_id": "cell-de2f3f6602aa13a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## 1.2 Explore categorical features <a class=\"anchor\" id=\"cat_features\"></a>\n",
    "\n",
    "\n",
    "We will start from creating a new feature called `Title`. By the title we mean the name prefix, such as `Mr`, `Miss`, `Dr` etc. It may tell us a lot about age or family status of the passenger even if this information is missing from the dataset. \n",
    "\n",
    "Let us take a look at some of the `Name` values. You can see that for each passenger name is organised as: \n",
    "\n",
    "```\n",
    "Surname, Title. Name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.Name[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ee0c245bf2ff2b4b5ddf539825964ce",
     "grade": false,
     "grade_id": "cell-659ab36c0b2d9999",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "**Task 1** [2 pts] Add a new column `Title` to the `titanic` dataframe. <a class=\"anchor\" id=\"task1\"></a>\n",
    "\n",
    "*Hints:* \n",
    "1. You need to extract part of the string from each value of the `Name` column\n",
    "2. `pandas.Series.str` has wide variaty of vectorized string functions. That is, if you run `titanic.Name.str.useful_function()`, then `useful_function()` will be applied to each element of the column `Name`. Take a look at the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.html) for more details and the list of \"useful functions\".\n",
    "3. You'll likelily need to apply regular expressions (but it is also to possible to do the task without it). Do not worry, it is nothing sophisticated. Here is all you need to know:\n",
    " * `[a-zA-Z]` - refers to any letter \n",
    " * `\\.` - refers to the dot\n",
    " * `\\,` - refers to the comma\n",
    " * `+` - means that the element repeats 1 or more times. E.g. `\\.+` means 1 or more dots\n",
    " * `\\s` - refers to any spacing sign \n",
    "4. Extract the title without the dot that goes after it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dca152e7ab7e2745bd1bd5b1c54c36e4",
     "grade": false,
     "grade_id": "cell-f91f30953488d53c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da69098e7723647f5011d1d535bb4f8a",
     "grade": true,
     "grade_id": "cell-4067a2abcca23a51",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(titanic['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9c9b83cdaa003df5c3395ef4c022e0d",
     "grade": false,
     "grade_id": "cell-e9206102af974de2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task2\"></a>\n",
    "You can see that some titles are very rare, which makes their usefulness questionable. We will now combine all the titles which has 6 or less observations into one category called `Other`.\n",
    "\n",
    "---\n",
    "**Task 2** [1 pt]. Create a vector `proper_titles` which contains all titles with > 6 observations. For all the passengers, who have title not from the `proper_titles` list, rename their `Title` to `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e606bb420c566178700085b81d9e2df3",
     "grade": false,
     "grade_id": "cell-47b93248f33ead1e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51dfd480a045fc39443cf44c2aa2d289",
     "grade": true,
     "grade_id": "cell-7198654d5aa00053",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(proper_titles)\n",
    "print()\n",
    "print(titanic.Title.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "W-Qq4H5oADeH",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b01f130ce357a8c785deb3e9efd973c1",
     "grade": false,
     "grade_id": "cell-ddab173c45e06018",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"task3\"></a>\n",
    "**Task 3** [1 pt] Obtain the list of all the categorical columns (columns with data type `object`). Name this list `categ_columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "deletable": false,
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1588936163340,
     "user": {
      "displayName": "Anna Kuzina",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiemaXGZADupTQf2gOFyfVMKD8BYzFXipMt2krfaeg=s64",
      "userId": "14976976853760262600"
     },
     "user_tz": -180
    },
    "id": "7zFhkTUf-neq",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ad6243175be4379eaa89bca7c2dc0a1",
     "grade": false,
     "grade_id": "cell-9c53839214569788",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "d30186ab-f6cb-42f6-85ef-738e67b7954c"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07ab2a7512ca1479d99247270bab92b3",
     "grade": true,
     "grade_id": "cell-5242f229019f70a9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(categ_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56c2f67551366e0e8c91ac64d42a7a9c",
     "grade": false,
     "grade_id": "cell-d43470d598f11ad2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us explore these categorical features in more details. We will use method `describe` to obtain some statistics about them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85ce8faa49c342101587efc09e623adf",
     "grade": false,
     "grade_id": "cell-061f497fa0776872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "titanic[categ_columns].describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5ed9d8c2f7e24c1829ad0fa6bd73f89",
     "grade": false,
     "grade_id": "cell-f56de32d30029803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Sometimes, categorical columns contain too many unique values, which do not have a lot of information about the task we are solving. There are cases, when it is possible to extract some useful details from such variables (as we just did with the `Name`). But if you can't it might be better to drop such variable. \n",
    "\n",
    "\n",
    "---\n",
    "<a class=\"anchor\" id=\"task4\"></a>\n",
    "**Task 4** [1 pt] Remove all the categorical features, which have more than 100 unique values. \n",
    "\n",
    "P.S. Remove the corresponding columns from the dataframe `titanic` and unpdate list of categorical feature `categ_columns` to contain only categorical features that are left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79cdfa052d730a6c1afc304e37b27a8a",
     "grade": false,
     "grade_id": "cell-2d21a7cb77daf9b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6c9bf52941ae6933ec3fed9d1e561b7",
     "grade": true,
     "grade_id": "cell-71c524a3b5756bce",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(categ_columns)\n",
    "\n",
    "titanic[categ_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17a50fabbe239e380ffeee2b17548a6b",
     "grade": false,
     "grade_id": "cell-8351e787208feef7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's consider distribution of all the categorical features now\n",
    "\n",
    "---\n",
    "<a class=\"anchor\" id=\"task5\"></a>\n",
    "**Task 5** [Peer Reviewed] For each categorical feature draw two bar plots side by side. On the first plot, height of the bar should depict number of passengers in each category, while on the second, height of the bar should depict propostion of survived passengers in the category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e969d354886b7e90cf3072db5b64aac3",
     "grade": false,
     "grade_id": "cell-090a99b82541ea3f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ec2eaaa24f9fe8214697bda3eba43de",
     "grade": true,
     "grade_id": "cell-fc4354b670ea4ecc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5d0c0106332fd5c13e38f806e080d6c",
     "grade": false,
     "grade_id": "cell-fae416b5f5ae6408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Peer Review Grading.** Below you can find the correct plots for this task. Please, compare them to the plots produced by the code above. Please, do not pay attention to the order in which graphs are ploted.\n",
    "\n",
    "<img src=\"correct_plot_Embarked.png\" width=600 height=600 />\n",
    "<img src=\"correct_plot_Sex.png\" width=600 height=600 />\n",
    "<img src=\"correct_plot_Title.png\" width=600 height=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b05828e2d3cd65cfffa095482de29be",
     "grade": false,
     "grade_id": "cell-7f0b8ac91af2ffb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## 1.3 Ordical and Numeric Features <a class=\"anchor\" id=\"rest_features\"></a>\n",
    "\n",
    "Now consider the rest of the dataset. Below you can see the first few observations from all the non-categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[[c for c in titanic.columns if c not in categ_columns + ['Survived']]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "S0VBjAXLE8i_",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bc89db7e21158ec38c7f358f03acd28a",
     "grade": false,
     "grade_id": "cell-05fd8fc062a95bf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"task6\"></a>\n",
    "**Task 6** [Peer graded] We suggest removing the feature `PassengerID` from the dataset. Please do it below and write your comment on why this is a resonalbe thing to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97fbe9cc58f3e15b94a6b26209a42a81",
     "grade": false,
     "grade_id": "cell-42648579773c6948",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Your comment here```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "685334fb067173dbd9a00c4afd15cc03",
     "grade": true,
     "grade_id": "cell-7d561bb892a04130",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'PassengerId' not in titanic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "928ff91f2c10ac22cce88b3c197390d6",
     "grade": false,
     "grade_id": "cell-7f0885ecf3fb9ff9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Peer Review Grading.** Please read the comment above and check the validity of the arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "faa030b4ddd558b778bf33ecde2b1b51",
     "grade": false,
     "grade_id": "cell-ff19344ea51e30dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "Consider two columns: `SibSp` and `Parch`. The first one is responsibel for number of Siblings/Spouses aboard the Titanic for the given passenger. The second one - number of parents/childer aboard the Titanic. Note that we can create one variable `FamilySize` out of these two. \n",
    "\n",
    "<a class=\"anchor\" id=\"task7\"></a>\n",
    "**Task 7** [1 pt] Create a variable `FamilySize` as a total size of the passenger's family aboard. Remove columns `SibSp` and `Parch` from the dataset afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae1c60433e0417b1648277280ddc6140",
     "grade": false,
     "grade_id": "cell-d93f717ddc47d367",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1176141d6dc6d3d2ab8a298dcbb12a48",
     "grade": true,
     "grade_id": "cell-1511c808b2ea4da4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "titanic.FamilySize.value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Family Size')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3698db6988f8d66d5f08a82bdc0bb270",
     "grade": false,
     "grade_id": "cell-f42e8dedc8e82c64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "Let us work with the variable `FamilySize` even further. Turns out, that sometimes it is reasonable to convert numerical feature into ordinal ones. E.g. instead of having a family size we can group peopple into `single`, `small_family`, etc. In this manner we can enforce larger distinction between people who do not have family at all and those who have small families. At the same time we can say that for the sake of our application we do not need to distiguish family of size 1 from the family of size 2. \n",
    "\n",
    "<a class=\"anchor\" id=\"task8\"></a>\n",
    "**Task 8** [Peer Graded]. Plot the bar plot for the variable `FamilySize` where the height of the bar is determined by the proportion of the survived passengers. Based on the created plot split all the passengers into tree groups. For each group create a binary variable `FamilySize_1`, `FamilySize_2` and `FamilySize_3`. Justify the split that you've chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f834da150645a3afdd0f1dda80d20705",
     "grade": false,
     "grade_id": "cell-4d78b5bcd190dec1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "322fa80be017a3c49096616ac69a5590",
     "grade": true,
     "grade_id": "cell-a45e239798cb5c68",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```your comment here```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb9eb3433e847752521d1534449c1a21",
     "grade": false,
     "grade_id": "cell-b05e96d8c3045393",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Peer Review Grading.** Please check that the plot above is correct (below you can see the correct answer). Also read the comment about the way the passengers were split on the groupd and check that the splitting is reasonable.\n",
    "\n",
    "<img src=\"task8_corrrect.png\" width=400 height=400 />\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Basically, we've just converted numerical feature `FamilySize` into categorical one with three categories. Moreover, we've simultaniously performed One-hot encoding of this categorical feature and obtained three binary variables. Now we can drop the feature `FamilySize` as it is not needed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(['FamilySize'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4cbdab376332b8e811d826aa13a4497",
     "grade": false,
     "grade_id": "cell-f0df55b128f58491",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "<a class=\"anchor\" id=\"task9\"></a>\n",
    "**Task 9** [1 pt]. We have three features left unexplored. They are `Pclass`, `Age` and `Fare`. The frist one stands for the ticket class, second - for the age of the passenger and the fird one gives us price of the ticket. \n",
    "\n",
    "Please, create `ordinal_cols`, which will be list of all the ordinal columns (put there names of relevant columns) and `numeric_cols` - list with the names of the numeric columns. If there is no ordinal or numeric colums, make the corrisponding list empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a5e31e9fe9c0f452057525055946085",
     "grade": false,
     "grade_id": "cell-532a4f54cf51bb15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14fed0958eb846408338b76d447281a4",
     "grade": true,
     "grade_id": "cell-ac29edf4d82e0459",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('Ordinal columns are: ', ordinal_cols)\n",
    "print('Numeric columns are: ', numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "xdHkCw7CN-JP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ac13d3fa5b542a55727decf815e9c91",
     "grade": false,
     "grade_id": "cell-8b443a15975c90a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can use different plots to explore numerical features. Below you can find some examples with the variable `Age`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1588942709565,
     "user": {
      "displayName": "Anna Kuzina",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiemaXGZADupTQf2gOFyfVMKD8BYzFXipMt2krfaeg=s64",
      "userId": "14976976853760262600"
     },
     "user_tz": -180
    },
    "id": "7fLiaQLSE9z4",
    "outputId": "1b72bbe2-664d-4e7c-cb42-6ed4dd32f16f"
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print('We can use histograms or boxplots to see how numerical features depends on the categorical one.')\n",
    "print('1. Age vs Target')\n",
    "titanic.hist(column='Age', by='Survived', bins=20, sharey=True);\n",
    "plt.show();\n",
    "\n",
    "print()\n",
    "print('2. Age vs Sex')\n",
    "titanic.boxplot(column='Age', by='Sex', figsize=(7,5));\n",
    "plt.ylabel('Age');\n",
    "plt.show();\n",
    "\n",
    "print('3. Age vs Target')\n",
    "titanic.boxplot(column='Age', by='Title', figsize=(7,5));\n",
    "plt.ylabel('Age');\n",
    "plt.show();\n",
    "\n",
    "print()\n",
    "print('Scatter plots are usefull to spot connection between two numeric features.')\n",
    "titanic.plot.scatter(x='Age', y='Fare');\n",
    "plt.grid()\n",
    "plt.title('Scatter plot of Age and Fare');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1588943213481,
     "user": {
      "displayName": "Anna Kuzina",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiemaXGZADupTQf2gOFyfVMKD8BYzFXipMt2krfaeg=s64",
      "userId": "14976976853760262600"
     },
     "user_tz": -180
    },
    "id": "vWgnGSowPLSm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55a06c8b7318f11ecca91ff684d85c96",
     "grade": false,
     "grade_id": "cell-1e34723320a6159f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "4b5b82cf-0747-44e3-abef-3b7d881eb30f"
   },
   "source": [
    "One reason, why it is usefull to make such plots is that it may help to fill in missing values. Keep it in mind for the next part of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "e8go58wc8rkp",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5997c2e39abd0173a60791dbbcda8c2f",
     "grade": false,
     "grade_id": "cell-9ee4600e50832a6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "## 1.3 working with missing values <a class=\"anchor\" id=\"na\"></a>\n",
    "<a class=\"anchor\" id=\"task10\"></a>\n",
    "**Task 10** [1 pts] Compute proportion of missing values in each column. Store the answer in the variable `prop_missing`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "deletable": false,
    "executionInfo": {
     "elapsed": 948,
     "status": "ok",
     "timestamp": 1588940619885,
     "user": {
      "displayName": "Anna Kuzina",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiemaXGZADupTQf2gOFyfVMKD8BYzFXipMt2krfaeg=s64",
      "userId": "14976976853760262600"
     },
     "user_tz": -180
    },
    "id": "LtQvp-FSp4hS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee795b3549f5bda94a46f708d3bb4591",
     "grade": false,
     "grade_id": "cell-8c2846899255e3df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "894e0742-a126-4244-8026-fae110172777"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3da38b4ea5d1d77ef53f38f9b0cffd01",
     "grade": true,
     "grade_id": "cell-65b3a6e89c523d51",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "print('Proportion of missing targets: {:.2f}'.format(prop_missing.Survived))\n",
    "print('Proportion of missing `Age` values: {:.2f}'.format(prop_missing.Age))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "deletable": false,
    "editable": false,
    "id": "k8n8kW9Z9iDm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47d8c17ace448924e0fc7d743e34280d",
     "grade": false,
     "grade_id": "cell-6f1656159b2630d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have two columns with missing values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.columns[prop_missing > 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd811f279ed8717721ca028b77f8fcc6",
     "grade": false,
     "grade_id": "cell-93223e6e1beacebc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task11\"></a>\n",
    "What can we do with that? Below you can find some options:\n",
    "- Fill all the NAs with the same value (mean, median, any other constant)\n",
    "- Fill NAs using grouping (e.g. we can fill missing in the variable `Fare` for male and female passengers separately using their average value)\n",
    "- Drop all the rows with missing values\n",
    "- Drop the whole column (e.g. if there are too many missing values)\n",
    "\n",
    "The most popular way is to use `SimpleImputer` from sklearn. If fills all the missing values with the same number. \n",
    "\n",
    "\n",
    "**Task 11** [2 pts] In this task we will implement a more phisticated Imputer. `MeanGroupImputer`. We will make sure that it has proper sklearn interface, so that we can use it within our pipelines. Below you can find the skeleton code for the `MeanGroupImputer`. Please read it carefully to make sure you understand everythig. Your task is to write missing code for the method `transform`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "550acd3a6517a6dc00df158f553680c5",
     "grade": false,
     "grade_id": "cell-5c83fb1c75d9bd6c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class MeanGroupImputer(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Class used for imputing missing values in a pd.DataFrame using mean value within group\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    group_cols : str\n",
    "        A column used to calculate the mean values\n",
    "    Returns\n",
    "    -------\n",
    "    X : array-like\n",
    "        The array with imputed values in the target column\n",
    "    '''\n",
    "    def __init__(self, group_col):\n",
    "        assert type(group_col) == str, 'group_col should be a string'\n",
    "\n",
    "        self.group_col = group_col\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        assert X[self.group_col].isna().sum() == 0, 'There are missing values in the group_col'\n",
    "        \n",
    "        # Group dataset by `group_col` and calculate mean value of all the other columns within this group\n",
    "        self.mapping = X.groupby(self.group_col).mean()\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        # make sure that the imputer was fitted\n",
    "        assert self.mapping is not None\n",
    "        \n",
    "        # loop over all the groups\n",
    "        for index, row in self.mapping.iterrows():\n",
    "            \n",
    "            # Fill in missing values for the group `index` with the values `row`            \n",
    "            # your code here\n",
    "            \n",
    "        \n",
    "        # Then drop grouping column (we did not transform it, so it is not needed anymore)\n",
    "        X.drop(self.group_col, axis=1, inplace=True)\n",
    "        return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b17de29282cf7dc18d71274001ecc8c",
     "grade": true,
     "grade_id": "cell-da989463096f240f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "toy_dataset = pd.DataFrame({'name': ['A','A', 'B','B','B','B', 'C','C','C'],\n",
    "                            'value': [1, np.nan, 2, np.nan, 3, 1, 3, np.nan, 5],\n",
    "                            'other_value': [10, np.nan, np.nan, 20, 30, 10, 30, np.nan, 30]})\n",
    "print(toy_dataset)\n",
    "imp = MeanGroupImputer(group_col='name')\n",
    "output = imp.fit_transform(toy_dataset)\n",
    "print(output)\n",
    "\n",
    "# test that answers are correct for the toy dataset\n",
    "assert (output[:, 0] == np.array([1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 5.0])).all()\n",
    "assert (output[:, 1] == np.array([10.0, 10.0, 20.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0])).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dc3d3e50cd755737ffcdc663fc2bbe3",
     "grade": false,
     "grade_id": "cell-dce865a64f265a1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.4 Define column transformers <a class=\"anchor\" id=\"columns\"></a>\n",
    "\n",
    " <a class=\"anchor\" id=\"task12\"></a>\n",
    " **Task 12** [2 pts] In this task we will define columns transformer. Your task is to create three pipelines:\n",
    " - `age_pipe`: Pipeline to preprocess column `Age`. It uses `MeanGroupImputer` with the grouping variable `Title` to fill missing values in `Age` and then applies `StandardScaler`\n",
    " - `fare_pipe`: Pipeline to preprocess column `Fare`. It applies `StandardScaler` only\n",
    " - `categ_pipe`: Pipeline to preprocess all categorical variables. It uses `SimpleImputer` to impute missing values with the most frequent class and then applies `OneHotEncoder`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f6bfb485b00188a3dd8179596704f4b",
     "grade": false,
     "grade_id": "cell-f79ada0c37790721",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "\n",
    "# Combine all three pipelines in one column transformer\n",
    "column_transformer = ColumnTransformer([\n",
    " ('age', age_pipe, ['Age', 'Title']),\n",
    " ('fare', fare_pipe, ['Fare']),\n",
    " ('all_categ', categ_pipe, categ_columns)],\n",
    "remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29207381987d300f95559c7dbbbe592c",
     "grade": true,
     "grade_id": "cell-1927282b574aede2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_titanic = column_transformer.fit_transform(titanic)\n",
    "print(pd.DataFrame(test_titanic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a93e375f0a53ff73f96f3559ce7fea7f",
     "grade": false,
     "grade_id": "cell-78fe5935f758ff1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.5 Train/test split <a class=\"anchor\" id=\"train_test\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78ee290189bbf6fd4435796185f87353",
     "grade": false,
     "grade_id": "cell-d50c1c521723f6e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr, te = train_test_split(titanic, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train = tr.Survived\n",
    "y_test = te.Survived\n",
    "X_train = tr.drop(['Survived'], axis=1)\n",
    "X_test = te.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9777bb200370b3e7acdfdf9535bf3b95",
     "grade": false,
     "grade_id": "cell-0a85e95d85f3491e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Logistic Regression and Support Vector Machine <a class=\"anchor\" id=\"part2\"></a>\n",
    "\n",
    "\n",
    "## 2.1 Fit Logistic Regression\n",
    "\n",
    " <a class=\"anchor\" id=\"task13\"></a>\n",
    "**Task 13** [1 pt] Define the `log_reg_pipe` - pipeline which applies `column_transformer` and fits logistic regression with the the hyperparameter `penalty='none'` (by default sklearn applies L2 regularization). Calculate the 5-fold cross-validation score (use `accuracy` as a scoring function). Save the result (average accuracy on cross-validation) in the variable `log_reg_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e22b0039452140c47c23dc1b5bb14ec",
     "grade": false,
     "grade_id": "cell-8bb06ad3b7e9aa39",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63a067cef3db736053ab57d87abe49da",
     "grade": true,
     "grade_id": "cell-d6e870a4329947b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(log_reg_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7b75739a8ab45a4ce506e58c2c3a097",
     "grade": false,
     "grade_id": "cell-6a5de7b77d2d21f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2 Fit Support Vector Machine\n",
    "\n",
    " <a class=\"anchor\" id=\"task14\"></a>\n",
    "**Task 14** [1 pt] Define the `svm_pipe` - pipeline which applies `column_transformer` and fits Support Vector Machine model (it is imported for you below) using the hyperparameter `kernel='linear'`. Calculate the 5-fold cross-validation score (use `accuracy` as a scoring function). Save the result (average accuracy on cross-validation) in the variable `svm_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c73bedb8efa0db4658719cb9b54f658f",
     "grade": false,
     "grade_id": "cell-e49424107e9226cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "461e57fc0417ee154ca52e5d7e00d301",
     "grade": true,
     "grade_id": "cell-86e3112caf998f12",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(svm_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bc68c7faf75fae7173a6be90802235f",
     "grade": false,
     "grade_id": "cell-e77c243f4e58c126",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.3 Compare different models\n",
    "\n",
    " <a class=\"anchor\" id=\"task15\"></a>\n",
    "**Task 15** [2 pts] In this task you are supposed to use grid search to find the best classifier for the given dataset. Use `GridSearchCV` class from sklearn. Use 5-Fold cross validation with accuracy as a scoring metric.\n",
    "\n",
    "*Hints*. Read documentation to see, which hyperparameters `LogisticRegression` and `SVC` have. Pay attention to `kernel` in the SVM model and the regularization coefficient `C` for both LogisticRegression and SVC, try different penalties for `LogisticRegression`. Explore other hyperparameters as well. Your task is to simply get the best accuracy posibe. The minimum passing value will be 0.84 (average score on cross-validaition)\n",
    "\n",
    "Please, do not use models other that `SVC` or `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "PQ0rvWbqz3qj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d88e4c27e6eb79a902de2c3623cd554e",
     "grade": false,
     "grade_id": "cell-ddf2a2bf617ee294",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82365d941f185ae851db8856e683a802",
     "grade": true,
     "grade_id": "cell-056b0f3a1fda6d1a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(grid_pipe.best_score_)\n",
    "print(grid_pipe.best_estimator_.steps[1][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "69fbf039e609592675c2bbac1c39551e",
     "grade": false,
     "grade_id": "cell-256ce340a7414671",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.4 Eval best model on test\n",
    "\n",
    "Now, we can use the best estimator to evaluate model on the test dataset. \n",
    "\n",
    "1. Fit model on the whole test data\n",
    "2. Make predictions on the test set\n",
    "3. Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "grid_pipe.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = grid_pipe.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8601c0db1a92141fccfc5eac75767689",
     "grade": false,
     "grade_id": "cell-f49a2cc882e90504",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Optional Part\n",
    "\n",
    "This homework is based on an extremely popular [Kaggle competition](https://www.kaggle.com/c/titanic/overview). We encourage you to use the result of this homework to get aquanted with this platform. Below, we provide a short instruction along with the list of useful link for those of you who are interested to learn more about it. \n",
    "\n",
    "1. Train the best model you can. Here you can use al the training data to perform cross-validation, because there is a separate `test set` provided by the competioint (We did not use it in the assignment, because there is not correct answers provided for this test dataset)\n",
    "2. Load the test dataset: `pd.read_csv(\"titanic_kaggle_test.csv\")`. We've saved this file for you on courserra labs already\n",
    "3. Do not forget to perform the same transformations you did with the train data (e.g. create new variables, deleting others, etc.)\n",
    "4. Make predictions for this dataset and save them as a csv file. You can find example of the submission file [here](https://www.kaggle.com/c/titanic/data)\n",
    "5. Submit your predictions on Kaggle (do not forget to register beforehand). After some time you will see your score! Do not worry if you are not on the first place of the [Leaderboard](https://www.kaggle.com/c/titanic/leaderboard). Consider solutions of other Data Scientists in the [Notebooks](https://www.kaggle.com/c/titanic/notebooks) section.\n",
    "\n",
    "```Good Luck!```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMLuDZqhJ6FOtzPDD92rePH",
   "collapsed_sections": [],
   "name": "Week 17. EDA and feature engineering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
